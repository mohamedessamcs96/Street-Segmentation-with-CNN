{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":34686,"sourceType":"datasetVersion","datasetId":27201}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport imageio\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = '/kaggle/input/lyft-udacity-challenge/dataa/dataA/CameraRGB/'\nmask_path = '/kaggle/input/lyft-udacity-challenge/dataa/dataA/CameraSeg/'\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N = 1\nimg = imageio.imread(image_list[N])\nmask = imageio.imread(mask_list[N])\nmask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(img)\narr[0].set_title('Image')\narr[1].imshow(mask, cmap='Paired')\narr[1].set_title('Segmentation')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"road = np.zeros((600, 800))\nroad[np.where(mask==7)[0], np.where(mask==7)[1]]=1\nplt.imshow(road)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"height, width = 600, 800\nimages = np.zeros((len(image_list), height, width, 3), dtype=np.int16)\nmasks = np.zeros((len(image_list), height, width, 1), dtype=np.int8)\n\nfor n in tqdm(range(len(image_list))):\n    img = imageio.imread(image_list[n])\n    \n    mask = imageio.imread(mask_list[n])\n    mask_road = np.zeros((600, 800, 1), dtype=np.int8)\n    mask_road[np.where(mask==7)[0], np.where(mask==7)[1]]=1\n    \n    images[n] = img\n    masks[n] = mask_road","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(images[1].reshape(600, 800, 3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(123)\nshuffle_ids = np.array([i for i in range(len(masks))])\nnp.random.shuffle(shuffle_ids)\ntrain_ids = shuffle_ids[:int(len(masks)*0.8)]\nval_ids = shuffle_ids[int(len(masks)*0.8):int(len(masks)*0.8+100)]\ntest_ids = shuffle_ids[int(len(masks)*0.8+100):]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images, train_masks = images[train_ids], masks[train_ids]\nval_images, val_masks = images[val_ids], masks[val_ids]\ntest_images, test_masks = images[test_ids], masks[test_ids]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images.shape, val_images.shape, test_images.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build U-Net with subtle changesÂ¶\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Lambda, RepeatVector, Reshape\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import backend as K","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build U-Net model\ninput_img = Input((height, width, 3), name='img')\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (input_img)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n\nu5 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c4)\nu5 = concatenate([u5, c3])\nc6 = Conv2D(32, (3, 3), activation='relu', padding='same') (u5)\nc6 = Conv2D(32, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c2])\nc7 = Conv2D(16, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(16, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c1])\nc8 = Conv2D(8, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(8, (3, 3), activation='relu', padding='same') (c8)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c8)\n\nmodel = Model(inputs=[input_img], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"callbacks = [\n    EarlyStopping(patience=12, verbose=1),\n    ReduceLROnPlateau(patience=3, verbose=1),\n    ModelCheckpoint('model-sdc-seg-v2.keras', verbose=1, save_best_only=True)\n]\n\nresults = model.fit(train_images, train_masks, batch_size=16, epochs=5, callbacks=callbacks,\n                    validation_data=(val_images, val_masks))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('final-road-seg-model-v2.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"NUMBER = 0\nmy_preds = model.predict(np.expand_dims(test_images[NUMBER], 0))\nmy_preds = my_preds.flatten()\nmy_preds = np.array([1 if i >= 0.5 else 0 for i in my_preds])\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax[0].imshow(my_preds.reshape(600, 800))\nax[0].set_title('Prediction')\nax[1].imshow(test_masks[NUMBER].reshape(600, 800))\nax[1].set_title('Ground truth')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}